{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca593541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base: C:\\Users\\Lenovo\\Desktop\\LY MAJOR PROJECT\n",
      "Images folder: C:\\Users\\Lenovo\\Desktop\\LY MAJOR PROJECT\\data\\images\n"
     ]
    }
   ],
   "source": [
    "# Notebook config (run this first cell)\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\Lenovo\\Desktop\\LY MAJOR PROJECT\")   # change if needed\n",
    "DATA = BASE / \"data\"\n",
    "IMAGES = DATA / \"images\"\n",
    "POP = DATA / \"population\"\n",
    "ROADS = DATA / \"roads\"\n",
    "BOUNDARIES = DATA / \"boundaries\"\n",
    "PROCESSED = DATA / \"processed\"\n",
    "PATCHES = DATA / \"patches\"\n",
    "OUTPUTS = BASE / \"outputs\"\n",
    "\n",
    "# Create folders (safe)\n",
    "for p in [PROCESSED, PATCHES, OUTPUTS, OUTPUTS/\"maps\", OUTPUTS/\"charts\"]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Base:\", BASE)\n",
    "print(\"Images folder:\", IMAGES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae0a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "model_path = r\"C:\\Users\\Lenovo\\Desktop\\LY MAJOR PROJECT\\data\\models\\urban_growth_unet.h5\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "predictions_dir = r\"C:\\Users\\Lenovo\\Desktop\\LY MAJOR PROJECT\\data\\predictions\"\n",
    "preds_file = os.path.join(predictions_dir, \"test_predictions.npz\")\n",
    "data = np.load(preds_file)\n",
    "preds, y_test = data[\"predictions\"], data[\"ground_truth\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb7bb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9919\n",
      "Precision: 0.9772\n",
      "Recall: 0.9961\n",
      "F1-Score: 0.9865\n",
      "IoU: 0.9735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n",
    "\n",
    "y_true_flat = y_test.flatten() > 0.5\n",
    "y_pred_flat = preds.flatten() > 0.5\n",
    "\n",
    "acc = accuracy_score(y_true_flat, y_pred_flat)\n",
    "prec = precision_score(y_true_flat, y_pred_flat)\n",
    "rec = recall_score(y_true_flat, y_pred_flat)\n",
    "f1 = f1_score(y_true_flat, y_pred_flat)\n",
    "iou = jaccard_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61449277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_7024\\975123403.py:26: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 5\n",
    "idxs = random.sample(range(len(preds)), n)\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "for i, idx in enumerate(idxs):\n",
    "    plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(y_test[idx, :, :, 0], cmap='gray')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, n, n + i + 1)\n",
    "    plt.imshow(preds[idx, :, :, 0], cmap='gray')\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, n, 2 * n + i + 1)\n",
    "    diff = np.abs(y_test[idx, :, :, 0] - preds[idx, :, :, 0])\n",
    "    plt.imshow(diff, cmap='hot')\n",
    "    plt.title(\"Difference\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Model Evaluation Visualization\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb9203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbangrowth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
